#!/usr/bin/env python3
"""
Aè‚¡åˆ†æç³»ç»Ÿå…¥å£è„šæœ¬

ç®€å•æ˜“ç”¨çš„å…¥å£æ–¹æ³•ï¼Œè¾“å…¥è‚¡ç¥¨ä»£ç å³å¯è¿è¡Œæ•´ä¸ªagents workflowç”Ÿæˆåˆ†ææ–‡æ¡£ã€‚
æ”¯æŒè¯¦ç»†æ—¥å¿—è¾“å‡ºï¼Œä¾¿äºé—®é¢˜æ’æŸ¥ã€‚

ä½¿ç”¨æ–¹æ³•:
    python -m tradingagents.analysis_stock_agent.main 002594
    python -m tradingagents.analysis_stock_agent.main 000001 --depth comprehensive --debug
"""

import os
import sys
import argparse
import logging
import traceback
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # python-dotenvæœªå®‰è£…æ—¶çš„æç¤ºï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼æ˜¾ç¤ºï¼‰
    pass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from tradingagents.analysis_stock_agent.graph.a_share_analysis_graph import AShareAnalysisGraph
from tradingagents.analysis_stock_agent.config.a_share_config import A_SHARE_DEFAULT_CONFIG
from tradingagents.analysis_stock_agent.utils.state_models import AnalysisDepth


def setup_logging(debug: bool = False, log_file: Optional[str] = None) -> None:
    """
    é…ç½®è¯¦ç»†çš„æ—¥å¿—è¾“å‡º
    
    Args:
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    log_level = logging.DEBUG if debug else logging.INFO
    
    # åˆ›å»ºæ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(log_level)
    console_handler.setFormatter(formatter)
    
    # æ ¹æ—¥å¿—å™¨é…ç½®
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)
    root_logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¦‚æœæŒ‡å®šäº†æ—¥å¿—æ–‡ä»¶ï¼‰
    if log_file:
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(log_level)
        file_handler.setFormatter(formatter)
        root_logger.addHandler(file_handler)
    
    # è®¾ç½®ç‰¹å®šæ¨¡å—çš„æ—¥å¿—çº§åˆ«
    if debug:
        logging.getLogger('tradingagents.analysis_stock_agent').setLevel(logging.DEBUG)
        logging.getLogger('langgraph').setLevel(logging.INFO)
        logging.getLogger('httpx').setLevel(logging.WARNING)
        logging.getLogger('urllib3').setLevel(logging.WARNING)
    else:
        logging.getLogger('tradingagents.analysis_stock_agent').setLevel(logging.INFO)
        logging.getLogger('langgraph').setLevel(logging.WARNING)
        logging.getLogger('httpx').setLevel(logging.ERROR)
        logging.getLogger('urllib3').setLevel(logging.ERROR)


def validate_stock_code(stock_code: str) -> bool:
    """
    éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç 
    """
    if not stock_code:
        return False
    
    # ç§»é™¤å¯èƒ½çš„å‰ç¼€
    clean_code = stock_code.strip().upper()
    if clean_code.startswith('SH') or clean_code.startswith('SZ'):
        clean_code = clean_code[2:]
    
    # æ£€æŸ¥é•¿åº¦å’Œæ ¼å¼
    if len(clean_code) != 6:
        return False
        
    if not clean_code.isdigit():
        return False
    
    return True


def save_analysis_report(stock_code: str, report: str, output_dir: str = "results") -> str:
    """
    ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        report: åˆ†ææŠ¥å‘Šå†…å®¹
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    import logging
    logger = logging.getLogger(__name__)
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not report or not isinstance(report, str):
        logger.error(f"âŒ æŠ¥å‘Šå†…å®¹ä¸ºç©ºæˆ–éå­—ç¬¦ä¸²ç±»å‹: {type(report)}")
        raise ValueError("æŠ¥å‘Šå†…å®¹ä¸èƒ½ä¸ºç©º")
    
    if not stock_code:
        logger.error("âŒ è‚¡ç¥¨ä»£ç ä¸ºç©º")
        raise ValueError("è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º")
    
    # è®°å½•æŠ¥å‘Šä¿¡æ¯
    logger.info(f"ğŸ“ å‡†å¤‡ä¿å­˜æŠ¥å‘Š: è‚¡ç¥¨ä»£ç ={stock_code}, å†…å®¹é•¿åº¦={len(report)}å­—ç¬¦")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"Aè‚¡åˆ†ææŠ¥å‘Š_{stock_code}_{timestamp}.md"
    filepath = Path(output_dir) / filename
    
    try:
        # ä¿å­˜æŠ¥å‘Š - ç¡®ä¿å®Œæ•´å†™å…¥
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report)
            f.flush()  # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
        
        # éªŒè¯ä¿å­˜ç»“æœ
        saved_size = filepath.stat().st_size
        logger.info(f"âœ… æŠ¥å‘Šä¿å­˜æˆåŠŸ: {filepath}")
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {saved_size} å­—èŠ‚ ({saved_size/1024:.2f} KB)")
        
        # éªŒè¯æ–‡ä»¶å†…å®¹å®Œæ•´æ€§
        with open(filepath, 'r', encoding='utf-8') as f:
            saved_content = f.read()
        
        if len(saved_content) != len(report):
            logger.error(f"âŒ æ–‡ä»¶ä¿å­˜ä¸å®Œæ•´ï¼åŸå§‹é•¿åº¦: {len(report)}, ä¿å­˜é•¿åº¦: {len(saved_content)}")
            raise Exception("æŠ¥å‘Šä¿å­˜ä¸å®Œæ•´")
        
        logger.info(f"âœ… æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡: {len(saved_content)}å­—ç¬¦")
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
        raise Exception(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    return str(filepath)


def run_stock_analysis(stock_code: str, 
                      config: Optional[Dict[str, Any]] = None,
                      analysis_depth: AnalysisDepth = AnalysisDepth.COMPREHENSIVE,
                      debug: bool = False) -> tuple[Dict[str, Any], str]:
    """
    è¿è¡Œè‚¡ç¥¨åˆ†æworkflow
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
        analysis_depth: åˆ†ææ·±åº¦
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        
    Returns:
        (æœ€ç»ˆçŠ¶æ€, ç»¼åˆåˆ†ææŠ¥å‘Š)
    """
    logger = logging.getLogger(__name__)
    logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨: {stock_code}")
    
    try:
        # ä½¿ç”¨é»˜è®¤é…ç½®æˆ–è‡ªå®šä¹‰é…ç½®
        analysis_config = config or A_SHARE_DEFAULT_CONFIG.copy()
        
        # åˆ›å»ºåˆ†æå›¾å®ä¾‹
        with AShareAnalysisGraph(config=analysis_config, debug=debug) as graph:
            logger.info("åˆ†æå›¾åˆå§‹åŒ–å®Œæˆ")
            
            # æ‰§è¡Œåˆ†æ
            final_state, comprehensive_report = graph.analyze_stock(
                stock_code=stock_code,
                analysis_depth=analysis_depth
            )
            
            logger.info(f"è‚¡ç¥¨ {stock_code} åˆ†æå®Œæˆ")
            return final_state, comprehensive_report
            
    except Exception as e:
        logger.error(f"åˆ†æè‚¡ç¥¨ {stock_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        raise


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Aè‚¡æŠ•èµ„åˆ†æå¤šAgentç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s 002594                           # åˆ†ææ¯”äºšè¿ª
  %(prog)s 000001 --debug                   # å¯ç”¨è°ƒè¯•æ¨¡å¼åˆ†æå¹³å®‰é“¶è¡Œ  
  %(prog)s 600036 --depth standard          # ä½¿ç”¨æ ‡å‡†æ·±åº¦åˆ†ææ‹›å•†é“¶è¡Œ
  %(prog)s 000858 --output ./reports        # æŒ‡å®šè¾“å‡ºç›®å½•
  %(prog)s 002415 --log analysis.log        # ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶
        """
    )
    
    parser.add_argument(
        'stock_code',
        help='è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: 002594, 000001, 600036)'
    )
    
    parser.add_argument(
        '--depth',
        choices=['basic', 'standard', 'comprehensive'],
        default='comprehensive',
        help='åˆ†ææ·±åº¦ (é»˜è®¤: comprehensive)'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œè¾“å‡ºè¯¦ç»†æ—¥å¿—'
    )
    
    parser.add_argument(
        '--output',
        default='results',
        help='è¾“å‡ºç›®å½• (é»˜è®¤: results)'
    )
    
    parser.add_argument(
        '--log',
        help='æ—¥å¿—æ–‡ä»¶è·¯å¾„ (å¯é€‰)'
    )
    
    parser.add_argument(
        '--config',
        help='è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼ï¼Œå¯é€‰)'
    )
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    setup_logging(debug=args.debug, log_file=args.log)
    logger = logging.getLogger(__name__)
    
    try:
        # éªŒè¯è‚¡ç¥¨ä»£ç 
        if not validate_stock_code(args.stock_code):
            logger.error(f"æ— æ•ˆçš„è‚¡ç¥¨ä»£ç : {args.stock_code}")
            logger.error("è‚¡ç¥¨ä»£ç åº”ä¸º6ä½æ•°å­—ï¼Œä¾‹å¦‚: 002594, 000001, 600036")
            sys.exit(1)
        
        # è§£æåˆ†ææ·±åº¦
        depth_mapping = {
            'basic': AnalysisDepth.BASIC,
            'standard': AnalysisDepth.STANDARD,
            'comprehensive': AnalysisDepth.COMPREHENSIVE
        }
        analysis_depth = depth_mapping[args.depth]
        
        # åŠ è½½è‡ªå®šä¹‰é…ç½®ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        config = None
        if args.config:
            import json
            with open(args.config, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"å·²åŠ è½½è‡ªå®šä¹‰é…ç½®: {args.config}")
        
        # æ˜¾ç¤ºåˆ†æå¼€å§‹ä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ” Aè‚¡æŠ•èµ„åˆ†æç³»ç»Ÿ")
        print(f"ğŸ“ˆ è‚¡ç¥¨ä»£ç : {args.stock_code}")
        print(f"ğŸ“Š åˆ†ææ·±åº¦: {args.depth}")
        print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}\n")
        
        # è¿è¡Œåˆ†æ
        final_state, comprehensive_report = run_stock_analysis(
            stock_code=args.stock_code,
            config=config,
            analysis_depth=analysis_depth,
            debug=args.debug
        )
        
        # ä¿å­˜åˆ†ææŠ¥å‘Š
        report_path = save_analysis_report(
            stock_code=args.stock_code,
            report=comprehensive_report,
            output_dir=args.output
        )
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\n{'='*60}")
        print(f"âœ… åˆ†æå®Œæˆ!")
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        print(f"ğŸ•’ å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯æ‘˜è¦
        if isinstance(final_state, dict):
            summary_info = []
            for key, value in final_state.items():
                if key == "information_integration" and isinstance(value, dict):
                    if "comprehensive_score" in value:
                        summary_info.append(f"ğŸ“Š ç»¼åˆè¯„åˆ†: {value['comprehensive_score']}")
                    if "investment_recommendation" in value:
                        summary_info.append(f"ğŸ’¡ æŠ•èµ„å»ºè®®: {value['investment_recommendation']}")
            
            if summary_info:
                print("\nğŸ“‹ åˆ†ææ‘˜è¦:")
                for info in summary_info:
                    print(f"   {info}")
        
        print(f"{'='*60}\n")
        
        # å¦‚æœè°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
        if args.debug:
            print("ğŸ”§ è°ƒè¯•ä¿¡æ¯:")
            print(f"   æœ€ç»ˆçŠ¶æ€é”®æ•°é‡: {len(final_state) if isinstance(final_state, dict) else 'N/A'}")
            print(f"   æŠ¥å‘Šé•¿åº¦: {len(comprehensive_report)} å­—ç¬¦")
            print()
        
        logger.info("åˆ†ææµç¨‹å…¨éƒ¨å®Œæˆ")
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­äº†åˆ†æè¿‡ç¨‹")
        print("\nâš ï¸  åˆ†æå·²è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
        
    except Exception as e:
        logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
        
        if args.debug:
            print("\nğŸ”§ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(traceback.format_exc())
        
        sys.exit(1)


if __name__ == "__main__":
    main()